{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from pprint import pprint\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"C:/Users/Wayne Gardner/Desktop/chromedriver/chromedriver.exe\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_info():\n",
    "    browser = init_browser()\n",
    "\n",
    "    # Visit the nasa mars news website\n",
    "    url = \"https://mars.nasa.gov/news\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    # Pause for page to load\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    \n",
    "    #Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text.\n",
    "    #Assign the text to variables that you can reference later.\n",
    "\n",
    "    headline = soup.find_all(\"div\", class_=\"content_title\")\n",
    "    news_title=headline[1].text\n",
    "    article = soup.find_all(\"div\", class_=\"article_teaser_body\")\n",
    "    news_p=article[0].text\n",
    "    \n",
    "    # Visit the url for JPL Featured Space Image\n",
    "    url2 = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    browser.visit(url2)\n",
    "\n",
    "    # Pause for page to load\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    \n",
    "    #navigate the site and find the image url for the current Featured Mars Image\n",
    "    #and assign the url string to a variable called featured_image_url.\n",
    "    relative_image_path = soup.find('article', class_=\"carousel_item\")['style']\n",
    "    relative_image_path_url=relative_image_path.split(\"('\", 1)[1].split(\"')\")[0]\n",
    "    featured_image_url = \"https://www.jpl.nasa.gov/\" + relative_image_path_url\n",
    "    \n",
    "    \n",
    "    # Visit the Mars Facts webpage\n",
    "    url3 = \"https://space-facts.com/mars/\"\n",
    "    browser.visit(url3)\n",
    "\n",
    "    # Pause for page to load\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html3 = browser.html\n",
    "    soup = bs(html3, \"html.parser\")\n",
    "    \n",
    "    #scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "    facts=soup.find_all(class_=\"column-2\")\n",
    "    eq_diam=facts[0].text\n",
    "    polar_diam=facts[1].text\n",
    "    mass=facts[2].text\n",
    "    moons = facts[3].text\n",
    "    orb_dist=facts[4].text\n",
    "    orb_period=facts[5].text\n",
    "    surf_temp=facts[6].text\n",
    "    first_rec=facts[7].text\n",
    "    rec_by=facts[8].text\n",
    "    \n",
    "    \n",
    "    #building fact table\n",
    "    mars_facts={\n",
    "        \"Equatorial Diameter\":eq_diam,\n",
    "        \"Polar Diameter\":polar_diam,\n",
    "        \"Mass\":mass,\n",
    "        \"Moons\":moons,\n",
    "        \"Orbit Distance\":orb_dist,\n",
    "        \"Orbit Period\":orb_period,\n",
    "        \"Surface Temp\":surf_temp,\n",
    "        \"First Record\":first_rec,\n",
    "        \"Recorded By\":rec_by\n",
    "    }\n",
    "    \n",
    "    # Visit the USGS Astrogeology site \n",
    "    url4 = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "    browser.visit(url4)\n",
    "\n",
    "    # Pause for page to load\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html4 = browser.html\n",
    "    soup = bs(html4, \"html.parser\")\n",
    "    \n",
    "    #obtain high resolution images for each of Mar's hemispheres.\n",
    "    #You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image\n",
    "    #for each hemisphere, pull the link to the page, go to that page, find the url\n",
    "    \n",
    "    base_url=\"https://astrogeology.usgs.gov\"\n",
    "    #save all urls for hemisphere image pages to a list, then go to the urls\n",
    "    #and pull the large image url & add to list\n",
    "    hemispheres=soup.find_all(\"a\",class_=\"itemLink product-item\")\n",
    "    total=0\n",
    "    urls=[]\n",
    "    hem_imgs=[]\n",
    "    for hemisphere in hemispheres:\n",
    "        url=base_url+hemispheres[total].attrs[\"href\"]\n",
    "        if url not in urls:\n",
    "            urls.append(url)\n",
    "        total = total + 1\n",
    "    for url in urls:\n",
    "        browser.visit(url)\n",
    "        time.sleep(1)\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        hem=soup.find_all(\"img\",class_=\"wide-image\")[0].attrs[\"src\"]\n",
    "        hem_imgs.append(hem)\n",
    "        \n",
    "    \n",
    "    #hemisphere image table\n",
    "    hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": base_url + hem_imgs[3]},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": base_url + hem_imgs[0]},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": base_url + hem_imgs[1]},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": base_url + hem_imgs[2]},\n",
    "    ]\n",
    "    \n",
    "#     print(news_title)\n",
    "#     print(\"-----\")\n",
    "#     print(news_p)\n",
    "#     print(\"-----\")\n",
    "#     print(featured_image_url)\n",
    "#     print(\"-----\")\n",
    "#     print(mars_facts)\n",
    "#     print(\"-----\")\n",
    "#     print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c6accd585bc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscrape_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-4c69d8e411a9>\u001b[0m in \u001b[0;36mscrape_info\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m#navigate the site and find the image url for the current Featured Mars Image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#and assign the url string to a variable called featured_image_url.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mrelative_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'article'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"carousel_item\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'style'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mrelative_image_path_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrelative_image_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"('\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"')\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mfeatured_image_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.jpl.nasa.gov/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_image_path_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "scrape_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
